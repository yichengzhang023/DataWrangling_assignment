{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Task 1 in Assessment 1\n",
    "#### Student Name: Yicheng Zhang\n",
    "#### Student ID: 27699641\n",
    "\n",
    "Date: 20/03/2018\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3.6.3 and Jupyter notebook\n",
    "\n",
    "Libraries used:\n",
    "* pandas (for dataframe, included in Anaconda Python 3.6) \n",
    "* re (for regular expression, included in Anaconda Python 3.6) \n",
    "* numpy (for numpy array, included in Anaconda Python 3.6)\n",
    "* sys (for system information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Parse EXCEL File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load Excel File\n",
    "First step of this assessment is loading the excel file's data from the file, In python, there are many methods to do this job, one of the optimized method is using the `pandas` build-in method named `ExcelFile()` \n",
    "This method load the file as the object store in memeory:\n",
    "```\n",
    "    <pandas.io.excel.ExcelFile at 0x251ab8a8128>\n",
    "```\n",
    "We create a object for this file named `excel_data`\n",
    "* Note: This method depend on the xlrd environment, First we should install this package using:\n",
    "```shell\n",
    "    pip install xlrd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data = pd.ExcelFile('basic_indicators.xlsx')\n",
    "excel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the sheets in the excel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data.sheet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Load Data to Dataframe\n",
    "After we load the file as object, we can use build-in method for parse desired sheet in the file using `file.parse()` \n",
    "```python\n",
    "    using df.head()\n",
    "```\n",
    "To check the data frame with method `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = excel_data.parse('Basic Indicators') #parse desired sheet in file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Processing Data \n",
    "Now we have the dataframe of the excel file. However, this dataframe contain many unexcpted data, such as: \n",
    "```\n",
    "Row 0, contain nothing but None value\n",
    "Columns Named: Unnamed:0\n",
    "Columns' Name are not normalized\n",
    "etc\n",
    "```\n",
    "First Drop all the columns and rows with only None value using:`dropna()`\n",
    "```\n",
    "0,define axis = 0 which are Columns \n",
    "1,define axis = 1 which are Rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(0, how = 'all')\n",
    "df = df.dropna(1, how = 'all')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the data from the dataframe may influence the index, we should reset index by `df.index()`,new index should be numbers of records after drop the data `range()` Create list from 0 to numbers of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.index = range(len(df.index)) #reset index for remaning records\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data, we only need the data for 202 countries,using the slices to check where required data begin and end\n",
    "```python\n",
    "    df[:4] #check first 4 rows\n",
    "    df[-35:-30] # check the last 30 rows to 35 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:4] #display rows 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[-35:-30] #display last 35-30 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data should begin with `Afghanistan`, end with `Zimbabwe`. The index for begin and end should be index[3] end with index[-34]\n",
    "\n",
    "**Drop other rows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(df.index[0:3])\n",
    "df = df.drop(df.index[-34:]) #drop useless rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reset the index again, check the validity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.index = range(len(df.index)) #reset index\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some problems in the dataframe:\n",
    "* Columns Names are meaningless\n",
    "* Some columns's data should be considered keeping or dropping.\n",
    "\n",
    "**Rename the columns, set the first column as the index(which are country names),drop the the first column after setting it as the index of the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(df['TABLE 1. BASIC INDICATORS'].values) #set country name as index\n",
    "df = df.drop('TABLE 1. BASIC INDICATORS', 1)  #drop original country name\n",
    "df.index.rename('Country Name', inplace=True) #reset index name\n",
    "df.columns = list(range(len(df.columns))) #rename colunms use numbers\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check and drop if there are still rows or columns contain only empty values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(0, how = 'all')\n",
    "df = df.dropna(1, how = 'all') #drop useless rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dataframe, it can be found that column named 13 and 15 contains only Empety value and `x`.\n",
    "\n",
    "Finding the `x`'s meaning in the original file:\n",
    "> x Data refer to years or periods other than those specified in the column heading.  Such data are not included in the calculation of regional and global averages, with the exception of 2005–2006 data from India. Estimates from data years prior to 2000 are not displayed.\n",
    "\n",
    "It can be found that `x` is a mark for data beside it, may influence the data of global caculations, we only concerned about single countries instead of global statistics, these two columns can be droped for this reason.\n",
    "\n",
    "**Drop these two columns and reset column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(13, axis=1)\n",
    "df = df.drop(15, axis=1) #drop useless rows\n",
    "df.columns = list(range(len(df.columns))) #rename colunms use numbers\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dataframe, it can be found that there are some data not numeric `–`.\n",
    "\n",
    "Finding the `–`'s meaning in the original file:\n",
    "> – Data not available.\n",
    "\n",
    "For processing purpose, this symbol should be None value or empty value.\n",
    "\n",
    "**Replace all the `–` to empty value using `numpy.nan` (Empty value store as float number)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('–', np.nan, inplace=True) #replace useless symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the dataframe if everything is fine**\n",
    "* There should be 202 country names, and the following 14 columns contain the different types of indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[40:45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Save the Data \n",
    "After check the rows and columns in the dataframe, we need to store these data to a CSV file which can be used in the future,`pandas` can use the method named `to_csv` to save the dataframe in the CSV file.\n",
    "\n",
    "There are some problems need to be considered:\n",
    "```python\n",
    "df[40:45]\n",
    "```\n",
    "```Côte d'Ivoire\n",
    "```\n",
    "Check a slice in the dataframe, there is a country name with speical latin Charcter `ô`, the default encoding of the `to_csv` method is `utf-8` which may not capable of displaying this charcter,changing the encoding to `utf-16 or utf-32`.\n",
    "\n",
    "As requirement, the data should be integer, the data in the dataframe is float, we should control the number of float digits, which should be 0 after dot in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./basic_indicators.csv',encoding='utf-16',sep='\\t', float_format = '%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above script and process, some conclusions can be drawn:\n",
    "* An excel file is structured using the `python pandas package` can easily load and process the files\n",
    "- - -\n",
    "* Not all the data in the file are useful or have meaning, We should check the data first, by observing the original files and dataframe.\n",
    "- - -\n",
    "* When save data to the CSV file, the encoding should be seriously considered for compatibility purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pandas](http://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html)\n",
    "- - -\n",
    "[tutorial from moodle](https://moodle.vle.monash.edu/course/view.php?id=42906&section=9#9)\n",
    "- - -\n",
    "[Google map API](https://xlrd.readthedocs.io/en/latest/)\n",
    "- - -\n",
    "[numpy](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
