{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Task 2 in Assessment 1\n",
    "#### Student Name: Yicheng Zhang\n",
    "#### Student ID: 27699641\n",
    "\n",
    "Date: 20/03/2018\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3.6.3 and Jupyter notebook\n",
    "\n",
    "Libraries used: \n",
    "* pandas (for dataframe, included in Anaconda Python 3.6) \n",
    "* re (for regular expression, included in Anaconda Python 3.6) \n",
    "* numpy (for numpy array, included in Anaconda Python 3.6) \n",
    "* pdftables(for parse pdf file, included pdftable.six in third party package)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pdftables import get_tables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parse PDF File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load PDF File\n",
    "Unlike the excel files, pdf files usually not well-structured, we need to use some third-party packages in python to Extract the data from the pdf file.\n",
    "In this case, we choose `pdftables`\n",
    "\n",
    "`pdftables` create list objects for each page store the records also as list object.\n",
    "\n",
    "`get_tables` is a method which can do the task specifically\n",
    "\n",
    "** Create Pdf file object, load the tables in the pdf using `get_tables` method **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFile = 'health.pdf'\n",
    "pdfobj = open(pdfFile, 'rb') #read pdf as object\n",
    "tables = get_tables(pdfobj) #extract tables from pdf file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Check the content in the tables **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for table in tables:\n",
    "    for row in table[:10]:\n",
    "        print (row)\n",
    "    print ('==========================\\n') #dsiplay the results extract from pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Check the content in the tables, for each page start with 5th row(Countries)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for table in tables:  #4 pages\n",
    "    for row in table[5:]:  # \n",
    "        if 'THE STATE' in row[0]:\n",
    "            break\n",
    "        if row[0] == 'SUMMARY':\n",
    "            print (row)\n",
    "            break\n",
    "        print (row)\n",
    "    print ('==========================\\n') #dsiplay desired results extract from pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Check number of records in each page**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tables[0]))\n",
    "print(len(tables[1]))\n",
    "print(len(tables[2]))\n",
    "print(len(tables[3])) #check the records from each tables(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Processing Data \n",
    "After obeserving the above results, some finding can be summarized:\n",
    "* It can be found that for first three pages, the effective data always begin in 5 element, end with total numbers minus 2 element(The last two records are empty)\n",
    "\n",
    "* For the last page, there are only 14 countries\n",
    "\n",
    "** Update the pages, create list object copy in case errors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "** Update the pages, create list object in case errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0] = tables[0][5:67] #First page Afghanistan to Fiji len-2 for Fiji\n",
    "tables[1] = tables[1][5:68] #Second page Finland to Nepal len-2 for Nepal\n",
    "tables[2] = tables[2][5:68] #Third page Netherland to Tuvalu len-2 for Tuvalu\n",
    "tables[3] = tables[3][5:19] #Fourth page Uganda to Zimbabwe 14 countries in final page\n",
    "page1 = tables[0].copy()\n",
    "page2 = tables[1].copy()\n",
    "page3 = tables[2].copy()\n",
    "page4 = tables[3].copy() #process the data in copy version in case errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Check the content in each page**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still many problems in the data using the data in page1,3 as example:\n",
    "```python\n",
    "['Afghanistan','63','89','53','3956','33','74','73','65','60','62',...]\n",
    "```\n",
    "the data in the position(index) 4 which is `3956` is not correct when we check the original pdf file. This data should be divded by `39` and `56`\n",
    "The reason for this, may caused by pdftables itself.\n",
    "- - -\n",
    "Similarily, this situation occur in page2 the position(index) 5\n",
    "```python\n",
    "['Finland', '100', '100', '100', '99','9999', '–', '99', '92',...]\n",
    "```\n",
    "- - -\n",
    "We can use the regular expression to split two numbers with 2 digits easily, it is nearly impossible to split a 1-digit number between two numbers, after we split by regular expression, we should using some method to check the result.\n",
    "\n",
    "For the above splits, index from 4-6, refer to the pdf file, it represent the `Use of basic sanitation services (%)` in 2015 with `total` `urban` `rural`, it can be known by common sense that `total` should between `urban` and `rural`, if the condition cannot be satisfied, there are high chance there may be some mistake, for instance, first is 1-digit number, second one have 2-digits.\n",
    "\n",
    "For the 4th page on the other hand, there are many merged mistakes in data.\n",
    "```python\n",
    "['Uganda397332','192817938978','82','82','0','78','78','07887','80','4781','62','78']\n",
    "```\n",
    "the data in position(index) 0,1,7,9 should respectively be:\n",
    "* `Uganda397332` to `Uganda`,`39`,`73`,`32`\n",
    "* `192817938978` to `19`,`28`,`17`,`93`,`89`,`78`\n",
    "* `07887` to `0`,`78`,`87`\n",
    "* `4781` to `47`,`81`\n",
    "- - -\n",
    "Using the regular expression can do this split job, however, there are some potential problem:\n",
    "1. There are some special charcter in the data, such as x,-\n",
    "2. Observing the data from the original file, the data are all percentage numbers, which means, the data range should inside 0 - 100,we can use a regular expression to match these numbers apply with for loop.\n",
    "3. After spliting, the results should be checked.\n",
    "```python\n",
    "['Venezuela (Bolivarian Republic of)979986','959872999884','82','88','53','84','84','47775','72x','38x–','–','–']\n",
    "```\n",
    "\n",
    "In this data, in index 7, the string is `47775`, the expected output should be `47` `7` `75`,if we use the regular expression to find all the number between 0-100, the output will be `47` `77` `5` which is incorrect.\n",
    "\n",
    "check the `75`, it refer `Protection at birth (PAB) against tetanus`, look at the references[1], in 2016, this data in the world should larger than 60%, because this data is the last one when split, if this number smaller than 10, it can be nearly assert there is a mistake in this record.\n",
    "\n",
    "** Using the regular expression to split and fill the records **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(page1)):\n",
    "    split = re.findall(r'(100+|[1-9][0-9]?x?|[–]|0)', page1[index].pop(4)) #split merged data in index 4\n",
    "    page1[index] = page1[index][:4] + split + page1[index][4:]\n",
    "page1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Check the potential error in page1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in page1:\n",
    "     if '–' not in record[5] and '–' not in record[6]:\n",
    "        if int(record[4]) > int(record[5]) and int(record[4])>int(record[6]): #when total bigger than both urban and rural\n",
    "                print(record)     #check potential error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be found that in the record with index4 and index5, error may exist, cause the `71` is a number represent total, which is not between `8` and `4`(`urban` and `rural`),this situation can be caused by the second number in index4 should be first number in index5\n",
    "\n",
    "** Try to fix the split error in page1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for record in page1:\n",
    "     if '–' not in record[5] and '–' not in record[6]:\n",
    "        if int(record[4]) > int(record[5]) and int(record[4])>int(record[6]): #when total bigger than both urban and rural\n",
    "                split1 = re.findall(r'(\\d)(\\d)', record[4]) \n",
    "                split2 = re.findall(r'(\\d)', record[5])\n",
    "                record[4] = split1[0][0]       #change index 4 to 1 digit\n",
    "                record[5] = split1[0][1]+split2[0][0] # change index 5 to 2 digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Double Check the split error in page1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in page1:\n",
    "     if '–' not in record[5] and '–' not in record[6]:\n",
    "        if int(record[4]) > int(record[5]) and int(record[4])>int(record[6]): #when total bigger than both urban and rural\n",
    "                print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** split page 2 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(page2)):\n",
    "    split = re.findall(r'(100+|[1-9][0-9]?x?|[–]|0)', page2[index].pop(5)) #split merged data in index 5\n",
    "    page2[index] = page2[index][:5] + split + page2[index][5:]\n",
    "page2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Check the potential error in page2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in page2:\n",
    "     if '–' not in record[5] and '–' not in record[6]:\n",
    "        if int(record[4]) > int(record[5]) and int(record[4])>int(record[6]) and len(record[6])<2: #when total bigger than both urban and rural\n",
    "                print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** split page 3 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index in range(len(page3)):\n",
    "    split = re.findall(r'(100+|[1-9][0-9]?x?|[–]|0)', page3[index].pop(4))#split merged data in index 4\n",
    "    page3[index] = page3[index][:4] + split + page3[index][4:]\n",
    "page3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Check the potential error in page3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in page3:\n",
    "     if '–' not in record[5] and '–' not in record[6]:\n",
    "        if int(record[4]) > int(record[5]) and int(record[4])>int(record[6])and len(record[6])<2: #when total bigger than both urban and rural\n",
    "                print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** split page 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index in range(len(page4)):\n",
    "    name = re.findall(r'[a-zA-Z()\\s]+', page4[index][0])\n",
    "    data_1_3 = re.findall(r'(100+|[1-9][0-9]?x?|[–]|0)', page4[index][0])\n",
    "    page4[index][0] = name[0]\n",
    "    page4[index] = page4[index][:1] + data_1_3 + page4[index][1:] \n",
    "    data_4_10 = re.findall(r'(100+|[1-9][0-9]?x?|[–]|0)', page4[index].pop(4))\n",
    "    page4[index] = page4[index][:4] + data_4_10 + page4[index][4:]\n",
    "    data_15_17 = re.findall(r'(100+|[1-9][0-9]?x?|[–]|0)', page4[index].pop(15))\n",
    "    page4[index] = page4[index][:15] + data_15_17 + page4[index][15:]\n",
    "    data_19_20 = re.findall(r'(100+|[1-9][0-9]?x?|[–]|0)', page4[index].pop(19))\n",
    "    page4[index] = page4[index][:19] + data_19_20 + page4[index][19:]\n",
    "page4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Check the potential error in page4 index[0],[1]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in page4:\n",
    "     if '–' not in record[5] and '–' not in record[6]:\n",
    "        if int(record[4]) > int(record[5]) and int(record[4])>int(record[6]): #when total bigger than both urban and rural\n",
    "                print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in page4:\n",
    "     if '–' not in record[2] and '–' not in record[3]:\n",
    "        if int(record[1]) > int(record[2]) and int(record[1])>int(record[3]): #when total bigger than both urban and rural\n",
    "                print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data in index[7] contain three data, we should check the last data in case there is a 1-digit number in the second data.(accroding to the regluar expression) The last data now in index[17] is `Protection at birth (PAB) against tetanus` and should not less than 60 refer to previous explnation(40 for 2015 data,we use 40 for assert error)\n",
    "\n",
    "** Check the potential error in page4 index[7]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for record in page4:\n",
    "     if '–' not in record[17]:\n",
    "        if int(record[17]) < 40: #data from WHO PAB 2015 (assert error if less than 40%)\n",
    "                print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data in index[9] contain two data, we should check if there are 1-digit data\n",
    "\n",
    "** Check the potential error in page4 index[9]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in page4:\n",
    "     if '–' not in record[18] and '–' not in record[19]:\n",
    "        if len(record[18]) < 2 or len(record[18])<2:\n",
    "                print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Try to fix the error which found in above **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in  page4:\n",
    "    if '–' not in record[17]:\n",
    "        if int(record[17]) < 40: #data from WHO PAB\n",
    "            split1 = re.findall(r'(\\d)(\\d)', record[16])\n",
    "            split2 = re.findall(r'(\\d)', record[17])\n",
    "            record[16] = split1[0][0]\n",
    "            record[17] = split1[0][1]+split2[0][0]\n",
    "            print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Double Check the split error in page4 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in page4:\n",
    "     if '–' not in record[17]:\n",
    "        if int(record[17]) < 40: \n",
    "                print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Add all the pages togther, check the records if numbers are correct **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpage = page1 + page2 + page3 + page4  # add all list togther\n",
    "len(newpage)  # check number of records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Check the data by compare it with original file **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in newpage:\n",
    "    print (row)\n",
    "    print ('==========================\\n') # check the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Using the build-in method of `Pandas` named `DataFrame()` create the dataframe by list objects **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(newpage) #convert list of lists to dataframe\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some speical charcters in the dataframe `x`\n",
    "Finding the `x`'s meaning in the original file:\n",
    "> x Data refer to years or periods other than those specified in the column heading. Such data are not included in the calculation of regional and global averages. Estimates from data years prior to 2000 are not displayed.\n",
    "\n",
    "It can be found that `x` is a mark for data beside it, may influence the data of global caculations, we only concerned about single countries instead of global statistics, the `x` should be dropped in this case.\n",
    "\n",
    "the replace method in dataframe also should compare and match `x` in data and replace it, the `regex` variable should be set as \n",
    "```python \n",
    "True\n",
    "```\n",
    "\n",
    "**Replace all the x in the data with empty and check the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('x','',regex=True,inplace=True) #replace all the x in dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dataframe, it can be found that there are some data not numeric `–`.\n",
    "\n",
    "Finding the `–`'s meaning in the original file:\n",
    "> – Data not available.\n",
    "\n",
    "For processing purpose, this symbol should be None value or empty value.\n",
    "\n",
    "**Replace all the `–` to empty value using `numpy.nan` (Empty value store as float number)**\n",
    "\n",
    "**Check the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.replace('–',np.nan,inplace=True) #replace all–in dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some problems in the dataframe:\n",
    "* Columns Names are meaningless\n",
    "* index should be reset\n",
    "\n",
    "**Rename the columns, set the first column as the index(which are country names),drop the the first column after setting it as the index of the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.set_index(data[0].values)\n",
    "data = data.drop(0,axis=1)\n",
    "data.columns = list(range(len(data.columns)))\n",
    "data.index.rename('Country Name', inplace=True)  #adjust dataframe similar with excel file\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Save the Data \n",
    "After check the rows and columns in the dataframe, we need to store these data to a CSV file which can be used in the future,`pandas` can use the method named `to_csv` to save the dataframe in the CSV file.\n",
    "\n",
    "similar with the Excel file, the encoding should also using the `utf-16` for display latin charcter purpose.\n",
    "\n",
    "As requirement, the data should be integer, the data in the dataframe is float, we should control the number of float digits, which should be 0 after dot in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./health.csv',encoding='utf-16',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above script and process, some conclusions can be drawn:\n",
    "* Extract data from a PDF file is very hard compare with the structured files, such as excel, csv. However, we can also use the exits package in python for extracting data from PDF. One of the solutions is `pdftables`. It can be found that even using the package, there are still many work to wrangling the data. \n",
    "- - -\n",
    "* Using the regular expression is an effective way to get required results for multiple similar errors in the data wrangling, However, there may exits some cases that cannot use the general term formula, we should double check the data before using the regular expression, ensure it cover all situation.\n",
    "- - -\n",
    "* Due to the limitation of the regular expression, data should be checked after using the regular expression. We should check these data by considering the relationship and meaning of data itself, to develop script to check and fix the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pandas](http://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html)\n",
    "- - -\n",
    "[pdftables](https://github.com/okfn/pdftables)\n",
    "_ __\n",
    "[python data structures](https://docs.python.org/3.6/tutorial/datastructures.html)\n",
    "- - -\n",
    "[tutorial on moodle](https://moodle.vle.monash.edu/course/view.php?id=42906&section=8#8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
